pkgbase = ollama-cuda
	pkgdesc = Create, run and share large language models (LLMs) with CUDA
	pkgver = 0.4.4
	pkgrel = 1
	url = https://github.com/ollama/ollama
	arch = x86_64
	license = MIT
	makedepends = clblast
	makedepends = cmake
	makedepends = git
	makedepends = go
	makedepends = pigz
	depends = cuda
	optdepends = nvidia-utils: monitor GPU usage with nvidia-smi
	provides = ollama
	conflicts = ollama
	source = git+https://github.com/ollama/ollama#tag=v0.4.4
	source = fix-cuda-runner.patch
	source = ollama-ld.conf
	source = ollama.service
	source = sysusers.conf
	source = tmpfiles.d
	b2sums = c2ae1e84915a4846bd3e509a57dbe6e852cc20d2f6df34427d657981dc6d6d11223442ea881fac911ffcc734049b75ef837c52ed1526a6f59fed6bb8ff86abf3
	b2sums = 22b966b4bead223d6d357a4aeb90dde2ad5bf3ae02d20639b724c1bd94256efbfd7c1365f87a800d17628b96afb74fdb5b55dffefd21c736c26e84938861ffcb
	b2sums = 121a7854b5a7ffb60226aaf22eed1f56311ab7d0a5630579525211d5c096040edbcfd2608169a4b6d83e8b4e4855dbb22f8ebf3d52de78a34ea3d4631b7eff36
	b2sums = 031e0809a7f564de87017401c83956d43ac29bd0e988b250585af728b952a27d139b3cad0ab1e43750e2cd3b617287d3b81efc4a70ddd61709127f68bd15eabd
	b2sums = 3aabf135c4f18e1ad745ae8800db782b25b15305dfeaaa031b4501408ab7e7d01f66e8ebb5be59fc813cfbff6788d08d2e48dcf24ecc480a40ec9db8dbce9fec
	b2sums = e8f2b19e2474f30a4f984b45787950012668bf0acb5ad1ebb25cd9776925ab4a6aa927f8131ed53e35b1c71b32c504c700fe5b5145ecd25c7a8284373bb951ed

pkgname = ollama-cuda
